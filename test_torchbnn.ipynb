{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "56dc6d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchbnn.modules.module import BayesModule\n",
    "from torchbnn.modules.linear import BayesLinear\n",
    "from torchbnn.utils import freeze, unfreeze\n",
    "from torch.nn.functional import relu, tanh\n",
    "import torchbnn\n",
    "import torch\n",
    "\n",
    "test_input = torch.randn(20)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "201bef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNN(BayesModule):\n",
    "    def __init__(self, action_dim, obs_dim, reward_dim, W_world_model=None):\n",
    "        super(BayesModule, self).__init__()\n",
    "\n",
    "        # is reward dim == 1 ???\n",
    "        self.in_features = action_dim + obs_dim\n",
    "        self.h_in_features = self.in_features + 64\n",
    "        self.h_out_features = self.h_in_features + 32\n",
    "        self.out_features = obs_dim + reward_dim\n",
    "\n",
    "        self.input_layer = BayesLinear(prior_mu=0, prior_sigma=1,\n",
    "                                       in_features=self.in_features,\n",
    "                                       out_features=self.h_in_features)\n",
    "        self.hidden_layer = BayesLinear(prior_mu=0, prior_sigma=1,\n",
    "                                        in_features=self.h_in_features,\n",
    "                                        out_features=self.h_out_features)\n",
    "        self.ouput_layer = BayesLinear(prior_mu=0, prior_sigma=1,\n",
    "                                       in_features=self.h_out_features,\n",
    "                                       out_features=self.out_features)\n",
    "\n",
    "        if W_world_model:\n",
    "            self.copy_params_from_world_model(W_world_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = relu(self.input_layer(x))\n",
    "        x = relu(self.hidden_layer(x))\n",
    "        x = self.ouput_layer(x)\n",
    "        return x\n",
    "\n",
    "    def copy_params_from_world_model(self, W):\n",
    "        try:\n",
    "            self.load_state_dict(W)\n",
    "        except BaseException:\n",
    "            print('non compatible W')\n",
    "\n",
    "    def deterministic_mode(self):\n",
    "        '''deterministic output'''\n",
    "        freeze(self)\n",
    "        \n",
    "    def stochatisc_mode(self):\n",
    "        '''stochatisc output'''\n",
    "        unfreeze(self)\n",
    "\n",
    "\n",
    "\n",
    "net = BNN(action_dim=10, obs_dim=10, reward_dim=1)\n",
    "net.deterministic_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "7f098b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  81.3517, -361.4016,  337.7245,  302.7568,  -37.9019,   44.4398,\n",
       "         -29.8435,   55.0830, -151.8567,  118.5528, -428.5110],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2d4e50d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREEZE\n",
      "first:  tensor([-142.6856, -154.8361, -362.0369,   63.5905, -372.0220,    9.6467,\n",
      "         375.8112,  313.8050, -168.6241,  169.5249,  277.2051],\n",
      "       grad_fn=<AddBackward0>)\n",
      "second:  tensor([-142.6856, -154.8361, -362.0369,   63.5905, -372.0220,    9.6467,\n",
      "         375.8112,  313.8050, -168.6241,  169.5249,  277.2051],\n",
      "       grad_fn=<AddBackward0>)\n",
      "UNFREEZE\n",
      "first:  tensor([ 304.5933,  431.0191, -203.6651,  216.2456, -108.9122,  -41.8183,\n",
      "         -41.3938,  -56.9498, -391.9138,   98.8383, -335.1754],\n",
      "       grad_fn=<AddBackward0>)\n",
      "second:  tensor([-250.9065,  701.5959, -173.7515,  197.5743, -163.2101, -200.6471,\n",
      "         553.5250,  110.7768, -351.0387, -447.2856,  233.4259],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torchbnn.utils.freeze(net)\n",
    "print('FREEZE')\n",
    "print('first: ', net(test))\n",
    "print('second: ', net(test))\n",
    "\n",
    "\n",
    "torchbnn.utils.unfreeze(net)\n",
    "print('UNFREEZE')\n",
    "print('first: ', net(test))\n",
    "print('second: ', net(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8b83512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMPLE PARAMETERS TEST\n",
    "net_params_first_query = dict(net.named_parameters())\n",
    "net_params_second_query = dict(net.named_parameters())\n",
    "net_params_key = list(net_params_first_query.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c4366760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in_layer.weight_mu',\n",
       " 'in_layer.weight_log_sigma',\n",
       " 'in_layer.bias_mu',\n",
       " 'in_layer.bias_log_sigma',\n",
       " 'hidden_layer.weight_mu',\n",
       " 'hidden_layer.weight_log_sigma',\n",
       " 'hidden_layer.bias_mu',\n",
       " 'hidden_layer.bias_log_sigma',\n",
       " 'out_layer.weight_mu',\n",
       " 'out_layer.weight_log_sigma',\n",
       " 'out_layer.bias_mu',\n",
       " 'out_layer.bias_log_sigma']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_params_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cfd269f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]]),\n",
       " tensor([[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]]),\n",
       " tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True]),\n",
       " tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True]),\n",
       " tensor([[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]]),\n",
       " tensor([[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]]),\n",
       " tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True]),\n",
       " tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True]),\n",
       " tensor([[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]]),\n",
       " tensor([[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]]),\n",
       " tensor([True, True, True, True, True, True, True, True, True, True, True]),\n",
       " tensor([True, True, True, True, True, True, True, True, True, True, True])]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[net_params_first_query[k] == net_params_second_query[k] for k in net_params_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8401650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = BasicNet(action_dim=10, obs_dim=10, reward_dim=1, W_world_model=net.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "90a13fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_layer.weight_mu': Parameter containing:\n",
       " tensor([[-0.1157,  0.1072, -0.1538,  ..., -0.0555, -0.0156, -0.1273],\n",
       "         [-0.0550, -0.2128,  0.0103,  ..., -0.0186,  0.1170, -0.0612],\n",
       "         [-0.1844, -0.0708, -0.0252,  ..., -0.1186, -0.1652, -0.2070],\n",
       "         ...,\n",
       "         [-0.1870,  0.1595, -0.1436,  ..., -0.0367, -0.0323, -0.2139],\n",
       "         [ 0.0441, -0.1508,  0.0981,  ..., -0.1064,  0.1030,  0.0827],\n",
       "         [ 0.0303,  0.2087,  0.0735,  ..., -0.1331, -0.1048, -0.0448]],\n",
       "        requires_grad=True),\n",
       " 'in_layer.weight_log_sigma': Parameter containing:\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       " 'in_layer.bias_mu': Parameter containing:\n",
       " tensor([-0.1026, -0.0030, -0.0679,  0.1733, -0.2041,  0.0486,  0.0939,  0.1831,\n",
       "         -0.0933,  0.1928, -0.0717, -0.1952, -0.1744, -0.1536,  0.1260, -0.2205,\n",
       "         -0.0455, -0.1526, -0.1036,  0.0115, -0.1838,  0.0815,  0.1770, -0.1154,\n",
       "          0.0632,  0.1030, -0.1821, -0.0503, -0.0821, -0.0178,  0.1760, -0.1806,\n",
       "         -0.1149,  0.0321, -0.0870,  0.2042, -0.2174,  0.0813,  0.0579, -0.1430,\n",
       "          0.2072, -0.2184,  0.0396,  0.0168, -0.1395, -0.2141, -0.0433,  0.0910,\n",
       "         -0.1279,  0.1525, -0.0696,  0.1299, -0.0713,  0.1857, -0.1402,  0.0838,\n",
       "         -0.0107,  0.0195,  0.0592, -0.0151, -0.1126,  0.0683, -0.1443, -0.0385,\n",
       "         -0.0346, -0.0427, -0.1058,  0.0377, -0.0179, -0.1270,  0.0758,  0.0035,\n",
       "         -0.2023, -0.1942, -0.0255,  0.1270,  0.0567, -0.1425, -0.1603, -0.1761,\n",
       "         -0.1436, -0.1780,  0.0214, -0.0568], requires_grad=True),\n",
       " 'in_layer.bias_log_sigma': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       " 'hidden_layer.weight_mu': Parameter containing:\n",
       " tensor([[ 0.0676, -0.0798,  0.0206,  ...,  0.0820,  0.0817,  0.0056],\n",
       "         [-0.0794, -0.1064, -0.0264,  ..., -0.0284,  0.0679, -0.0498],\n",
       "         [-0.0639,  0.0184, -0.0176,  ..., -0.0159, -0.0272, -0.1083],\n",
       "         ...,\n",
       "         [-0.0344,  0.0144,  0.0007,  ...,  0.0990,  0.0993, -0.0039],\n",
       "         [ 0.0337,  0.1025, -0.0839,  ..., -0.0503, -0.0141, -0.0055],\n",
       "         [-0.0350,  0.0974, -0.0753,  ...,  0.0694,  0.0837,  0.0586]],\n",
       "        requires_grad=True),\n",
       " 'hidden_layer.weight_log_sigma': Parameter containing:\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       " 'hidden_layer.bias_mu': Parameter containing:\n",
       " tensor([ 0.0198,  0.0013, -0.0871, -0.0797, -0.0611, -0.0531, -0.0925, -0.0450,\n",
       "         -0.0907, -0.0138, -0.0506,  0.0516, -0.0825, -0.0918,  0.0556,  0.0258,\n",
       "         -0.0950, -0.0331,  0.0527, -0.0672,  0.0436, -0.0284,  0.0683,  0.0971,\n",
       "         -0.1029,  0.0403,  0.0128,  0.0013,  0.0845,  0.0112, -0.1070, -0.0544,\n",
       "          0.0369,  0.0394, -0.0818,  0.0540, -0.0928, -0.1015, -0.0386,  0.0665,\n",
       "         -0.1079,  0.1006, -0.0304, -0.0651, -0.0342,  0.0300,  0.0010,  0.0279,\n",
       "         -0.0706,  0.0436,  0.0123, -0.0884, -0.0028, -0.0161, -0.0759,  0.1059,\n",
       "          0.0978, -0.0044, -0.0210, -0.0620, -0.1073, -0.1017,  0.1059,  0.0358,\n",
       "          0.0880, -0.0139, -0.0957,  0.0619, -0.0527, -0.1022,  0.0211,  0.0515,\n",
       "          0.0870,  0.0692, -0.0326,  0.0149,  0.0467, -0.0526,  0.0832, -0.0889,\n",
       "          0.0190,  0.0877,  0.1030,  0.1039,  0.0007, -0.0153,  0.0891, -0.0240,\n",
       "         -0.0264, -0.0970, -0.0378, -0.0122, -0.0436, -0.0116, -0.0777, -0.0562,\n",
       "         -0.0504,  0.0813, -0.0672, -0.0145,  0.0054, -0.0274,  0.0535, -0.0544,\n",
       "         -0.0590,  0.1060, -0.0936,  0.0419, -0.0458,  0.0222, -0.0363, -0.0923,\n",
       "         -0.0748,  0.0423, -0.1003,  0.0556], requires_grad=True),\n",
       " 'hidden_layer.bias_log_sigma': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        requires_grad=True),\n",
       " 'out_layer.weight_mu': Parameter containing:\n",
       " tensor([[-0.0251, -0.0002,  0.0616,  ..., -0.0153,  0.0491, -0.0105],\n",
       "         [ 0.0441,  0.0617,  0.0616,  ...,  0.0584,  0.0905,  0.0331],\n",
       "         [-0.0209,  0.0019, -0.0798,  ..., -0.0143,  0.0540,  0.0516],\n",
       "         ...,\n",
       "         [ 0.0180, -0.0697, -0.0086,  ..., -0.0286, -0.0806, -0.0665],\n",
       "         [-0.0750, -0.0092,  0.0922,  ...,  0.0825, -0.0253,  0.0712],\n",
       "         [-0.0708,  0.0696,  0.0659,  ...,  0.0166,  0.0861,  0.0767]],\n",
       "        requires_grad=True),\n",
       " 'out_layer.weight_log_sigma': Parameter containing:\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True),\n",
       " 'out_layer.bias_mu': Parameter containing:\n",
       " tensor([-0.0281,  0.0531, -0.0765,  0.0620, -0.0324, -0.0078, -0.0723, -0.0794,\n",
       "         -0.0265,  0.0267,  0.0517], requires_grad=True),\n",
       " 'out_layer.bias_log_sigma': Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_params_first_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7fcd5def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('in_layer.weight_mu',\n",
       "              tensor([[-0.1157,  0.1072, -0.1538,  ..., -0.0555, -0.0156, -0.1273],\n",
       "                      [-0.0550, -0.2128,  0.0103,  ..., -0.0186,  0.1170, -0.0612],\n",
       "                      [-0.1844, -0.0708, -0.0252,  ..., -0.1186, -0.1652, -0.2070],\n",
       "                      ...,\n",
       "                      [-0.1870,  0.1595, -0.1436,  ..., -0.0367, -0.0323, -0.2139],\n",
       "                      [ 0.0441, -0.1508,  0.0981,  ..., -0.1064,  0.1030,  0.0827],\n",
       "                      [ 0.0303,  0.2087,  0.0735,  ..., -0.1331, -0.1048, -0.0448]])),\n",
       "             ('in_layer.weight_log_sigma',\n",
       "              tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      ...,\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.]])),\n",
       "             ('in_layer.bias_mu',\n",
       "              tensor([-0.1026, -0.0030, -0.0679,  0.1733, -0.2041,  0.0486,  0.0939,  0.1831,\n",
       "                      -0.0933,  0.1928, -0.0717, -0.1952, -0.1744, -0.1536,  0.1260, -0.2205,\n",
       "                      -0.0455, -0.1526, -0.1036,  0.0115, -0.1838,  0.0815,  0.1770, -0.1154,\n",
       "                       0.0632,  0.1030, -0.1821, -0.0503, -0.0821, -0.0178,  0.1760, -0.1806,\n",
       "                      -0.1149,  0.0321, -0.0870,  0.2042, -0.2174,  0.0813,  0.0579, -0.1430,\n",
       "                       0.2072, -0.2184,  0.0396,  0.0168, -0.1395, -0.2141, -0.0433,  0.0910,\n",
       "                      -0.1279,  0.1525, -0.0696,  0.1299, -0.0713,  0.1857, -0.1402,  0.0838,\n",
       "                      -0.0107,  0.0195,  0.0592, -0.0151, -0.1126,  0.0683, -0.1443, -0.0385,\n",
       "                      -0.0346, -0.0427, -0.1058,  0.0377, -0.0179, -0.1270,  0.0758,  0.0035,\n",
       "                      -0.2023, -0.1942, -0.0255,  0.1270,  0.0567, -0.1425, -0.1603, -0.1761,\n",
       "                      -0.1436, -0.1780,  0.0214, -0.0568])),\n",
       "             ('in_layer.bias_log_sigma',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('hidden_layer.weight_mu',\n",
       "              tensor([[ 0.0676, -0.0798,  0.0206,  ...,  0.0820,  0.0817,  0.0056],\n",
       "                      [-0.0794, -0.1064, -0.0264,  ..., -0.0284,  0.0679, -0.0498],\n",
       "                      [-0.0639,  0.0184, -0.0176,  ..., -0.0159, -0.0272, -0.1083],\n",
       "                      ...,\n",
       "                      [-0.0344,  0.0144,  0.0007,  ...,  0.0990,  0.0993, -0.0039],\n",
       "                      [ 0.0337,  0.1025, -0.0839,  ..., -0.0503, -0.0141, -0.0055],\n",
       "                      [-0.0350,  0.0974, -0.0753,  ...,  0.0694,  0.0837,  0.0586]])),\n",
       "             ('hidden_layer.weight_log_sigma',\n",
       "              tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      ...,\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.]])),\n",
       "             ('hidden_layer.bias_mu',\n",
       "              tensor([ 0.0198,  0.0013, -0.0871, -0.0797, -0.0611, -0.0531, -0.0925, -0.0450,\n",
       "                      -0.0907, -0.0138, -0.0506,  0.0516, -0.0825, -0.0918,  0.0556,  0.0258,\n",
       "                      -0.0950, -0.0331,  0.0527, -0.0672,  0.0436, -0.0284,  0.0683,  0.0971,\n",
       "                      -0.1029,  0.0403,  0.0128,  0.0013,  0.0845,  0.0112, -0.1070, -0.0544,\n",
       "                       0.0369,  0.0394, -0.0818,  0.0540, -0.0928, -0.1015, -0.0386,  0.0665,\n",
       "                      -0.1079,  0.1006, -0.0304, -0.0651, -0.0342,  0.0300,  0.0010,  0.0279,\n",
       "                      -0.0706,  0.0436,  0.0123, -0.0884, -0.0028, -0.0161, -0.0759,  0.1059,\n",
       "                       0.0978, -0.0044, -0.0210, -0.0620, -0.1073, -0.1017,  0.1059,  0.0358,\n",
       "                       0.0880, -0.0139, -0.0957,  0.0619, -0.0527, -0.1022,  0.0211,  0.0515,\n",
       "                       0.0870,  0.0692, -0.0326,  0.0149,  0.0467, -0.0526,  0.0832, -0.0889,\n",
       "                       0.0190,  0.0877,  0.1030,  0.1039,  0.0007, -0.0153,  0.0891, -0.0240,\n",
       "                      -0.0264, -0.0970, -0.0378, -0.0122, -0.0436, -0.0116, -0.0777, -0.0562,\n",
       "                      -0.0504,  0.0813, -0.0672, -0.0145,  0.0054, -0.0274,  0.0535, -0.0544,\n",
       "                      -0.0590,  0.1060, -0.0936,  0.0419, -0.0458,  0.0222, -0.0363, -0.0923,\n",
       "                      -0.0748,  0.0423, -0.1003,  0.0556])),\n",
       "             ('hidden_layer.bias_log_sigma',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('out_layer.weight_mu',\n",
       "              tensor([[-0.0251, -0.0002,  0.0616,  ..., -0.0153,  0.0491, -0.0105],\n",
       "                      [ 0.0441,  0.0617,  0.0616,  ...,  0.0584,  0.0905,  0.0331],\n",
       "                      [-0.0209,  0.0019, -0.0798,  ..., -0.0143,  0.0540,  0.0516],\n",
       "                      ...,\n",
       "                      [ 0.0180, -0.0697, -0.0086,  ..., -0.0286, -0.0806, -0.0665],\n",
       "                      [-0.0750, -0.0092,  0.0922,  ...,  0.0825, -0.0253,  0.0712],\n",
       "                      [-0.0708,  0.0696,  0.0659,  ...,  0.0166,  0.0861,  0.0767]])),\n",
       "             ('out_layer.weight_log_sigma',\n",
       "              tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      ...,\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "                      [0., 0., 0.,  ..., 0., 0., 0.]])),\n",
       "             ('out_layer.bias_mu',\n",
       "              tensor([-0.0281,  0.0531, -0.0765,  0.0620, -0.0324, -0.0078, -0.0723, -0.0794,\n",
       "                      -0.0265,  0.0267,  0.0517])),\n",
       "             ('out_layer.bias_log_sigma',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VBLRL_home",
   "language": "python",
   "name": "vblrl_home"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
