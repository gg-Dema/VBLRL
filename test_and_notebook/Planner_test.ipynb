{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e596838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bnn import BNN\n",
    "from cem_optimizer_v2 import CEM_opt\n",
    "from Propagation import Propagation_net\n",
    "from collections import deque\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95a7740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 10\n",
    "\n",
    "cem = CEM_opt(\n",
    "    num_action_seq=20,\n",
    "    action_seq_len=4 * horizon, \n",
    "    percent_elite=0.1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6df1f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dema/PycharmProjects/lifelong_rl/venv/lib/python3.10/site-packages/gym/spaces/box.py:127: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float64\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "/home/dema/PycharmProjects/lifelong_rl/venv/lib/python3.10/site-packages/gym/spaces/box.py:127: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    }
   ],
   "source": [
    "from metaworld.envs import (ALL_V2_ENVIRONMENTS_GOAL_OBSERVABLE)\n",
    "\n",
    "env = ALL_V2_ENVIRONMENTS_GOAL_OBSERVABLE['reach-wall-v2-goal-observable']()    \n",
    "s = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d22a97f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3092079897672715"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def apply(act_seq, s, env):\n",
    "    act_seq = act_seq.reshape((-1, 4))\n",
    "    cumulate_rew = 0\n",
    "    for act in act_seq: \n",
    "        s_prime, r, d, info = env.step(act)\n",
    "        s = s_prime\n",
    "        cumulate_rew += r\n",
    "    return cumulate_rew/act_seq.shape[0]\n",
    "\n",
    "def apply_rand(act_seq, s, env):\n",
    "    act_seq = act_seq.reshape((-1, 4))\n",
    "    cumulate_rew = 0\n",
    "    for act in act_seq: \n",
    "        s_prime, r, d, info = env.step(act + np.random.randn(4)*0.5)\n",
    "        s = s_prime\n",
    "        cumulate_rew += r\n",
    "    return cumulate_rew/act_seq.shape[0]\n",
    "\n",
    "\n",
    "act_sequence = cem.population\n",
    "s = env.reset()\n",
    "apply(act_sequence[0], s, env) # DETERMINISTIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e43d4931",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_act_seq = act_sequence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "63ea5c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3062740872594738"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_for_act_seq = []\n",
    "for particle in range(20):\n",
    "    s = env.reset()\n",
    "    avg_reward = apply_rand(reference_act_seq, s, env)\n",
    "    reward_for_act_seq.append(avg_reward)\n",
    "\n",
    "sum(reward_for_act_seq)/len(reward_for_act_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e7f2252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "propagation_net = Propagation_net(\n",
    "            num_particles=20,\n",
    "            action_dim=4,\n",
    "            obs_dim=39\n",
    "        )\n",
    "propagation_net.move_to_gpu()\n",
    "dynamic_dict = torch.load('model_stock/dynamic_small_evn_25_lr0.001_3000EP.pth')\n",
    "dynamic_net = BNN(action_dim=4, obs_dim=39, reward_dim=1, weight=dynamic_dict).to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "986daeff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3926, device='cuda:0')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "propagation_net.sample_from(dynamic_net)\n",
    "propagation_net.propagate(torch.from_numpy(s).to(DEVICE), torch.from_numpy(reference_act_seq).to(DEVICE))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90f31d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VBLRL",
   "language": "python",
   "name": "vblrl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
